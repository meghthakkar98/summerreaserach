# -*- coding: utf-8 -*-
"""knee main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mrmeIyG3mrwVIpb4T6UTQ74oZhvP5Nzq
"""

import torch
import torchvision
import torchvision.transforms as transforms
from torchvision import datasets, models
import matplotlib.pyplot as plt
import numpy as np
import os
from torch.utils.data import DataLoader, Dataset
from PIL import Image

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

csv_path = '/C:/Depaul university/CV/summer pro/main/clean_data.csv'  # Path to the uploaded CSV file
labels_path = '/C:/Depaul university/CV/summer pro/main/labels.csv'

# Load the CSV files
clean_data_df = pd.read_csv(csv_path)
labels_df = pd.read_csv(labels_path)

# Fill NaNs and convert to string
labels_df['labels'] = labels_df['labels'].astype(str).fillna('')

# Process the labels column to convert it to binary labels
def process_labels(label_str):
    if 'Edema' in label_str:
        return 1
    else:
        return 0

labels_df['label'] = labels_df['labels'].apply(process_labels)

# Merge the dataframes on 'image_path' or appropriate column
merged_df = pd.merge(clean_data_df, labels_df, on='image_path')

# Save the merged DataFrame to a new CSV file
merged_csv_path = '/C:/Depaul university/CV/summer pro/main/merged_clean_data.csv'
merged_df.to_csv(merged_csv_path, index=False)

# Display the first few rows of the merged DataFrame
print("Merged Data CSV:")
print(merged_df.head())

import pandas as pd
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import os
import torch
from torchvision import transforms, models
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Define the Dataset class
class KneeMRIDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.data_frame = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.data_frame)

    def __getitem__(self, idx):
        img_path = self.data_frame.iloc[idx]['image_path']
        img_name = os.path.join(self.root_dir, img_path)
        if not os.path.exists(img_name):
            print(f"Image path {img_name} does not exist.")
            return None, None

        image = Image.open(img_name).convert('L')  # Keep the image in grayscale

        if self.transform:
            image = self.transform(image)

        # Ensure image has 3 channels by repeating the grayscale channel
        image = image.repeat(3, 1, 1)

        label = self.data_frame.iloc[idx]['labels']
        return image, label

# Define the transform to resize the images and add data augmentation
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),
    transforms.ToTensor()
])

# Define the root directory of the images in Google Drive
root_dir = '/C:/Depaul university/CV/summer pro/main/images'  # Update this to the actual path in your Google Drive
merged_csv_path = '/C:/Depaul university/CV/summer pro/main/merged_clean_data.csv'  # Path to the merged CSV file

# Create the dataset
full_dataset = KneeMRIDataset(csv_file=merged_csv_path, root_dir=root_dir, transform=transform)

# Filter out None values due to missing images
filtered_dataset = [(img, lbl) for img, lbl in (full_dataset[i] for i in range(len(full_dataset))) if img is not None]

# Split the dataset into training and validation sets
train_size = int(0.8 * len(filtered_dataset))
val_size = len(filtered_dataset) - train_size

train_dataset, val_dataset = torch.utils.data.random_split(filtered_dataset, [train_size, val_size])

# Create data loaders
batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=lambda x: x)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=lambda x: x)

# Define the neural network model
class ModifiedResNet50(nn.Module):
    def __init__(self):
        super(ModifiedResNet50, self).__init__()
        self.base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
        num_ftrs = self.base_model.fc.in_features
        self.base_model.fc = nn.Linear(num_ftrs, 1)  # Single output for binary classification
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.base_model(x)
        x = self.dropout(x)
        return x

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = ModifiedResNet50().to(device)

criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy with Logits
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
num_epochs = 50

train_losses = []
val_losses = []
val_accuracies = []
all_preds = []
all_labels = []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for batch in train_loader:
        inputs, labels = zip(*[(img, lbl) for img, lbl in batch if img is not None])
        if len(inputs) == 0:
            continue
        inputs = torch.stack(inputs).to(device)
        labels = torch.tensor(labels).to(device).float().view(-1, 1)  # Ensure labels have shape [batch_size, 1]

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * inputs.size(0)

    epoch_loss = running_loss / len(train_loader.dataset)
    train_losses.append(epoch_loss)

    model.eval()
    val_running_loss = 0.0
    corrects = 0
    for batch in val_loader:
        inputs, labels = zip(*[(img, lbl) for img, lbl in batch if img is not None])
        if len(inputs) == 0:
            continue
        inputs = torch.stack(inputs).to(device)
        labels = torch.tensor(labels).to(device).float().view(-1, 1)

        with torch.no_grad():
            outputs = model(inputs)
            loss = criterion(outputs, labels)

        val_running_loss += loss.item() * inputs.size(0)
        preds = torch.round(torch.sigmoid(outputs))
        corrects += torch.sum(preds == labels.data)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

    val_loss = val_running_loss / len(val_loader.dataset)
    val_losses.append(val_loss)

    val_acc = corrects.double() / len(val_loader.dataset)
    val_accuracies.append(val_acc.item())

    print(f"Epoch {epoch}/{num_epochs - 1}, "
          f"Train Loss: {epoch_loss:.4f}, "
          f"Val Loss: {val_loss:.4f}, "
          f"Val Acc: {val_acc:.4f}")

# Plot the training and validation losses
plt.figure(figsize=(12, 6))
plt.plot(range(num_epochs), train_losses, label='Train Loss')
plt.plot(range(num_epochs), val_losses, label='Val Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

# Plot the validation accuracy
plt.figure(figsize=(12, 6))
plt.plot(range(num_epochs), val_accuracies, label='Val Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Validation Accuracy')
plt.legend()
plt.show()

# Generate confusion matrix
cm = confusion_matrix(all_labels, all_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()